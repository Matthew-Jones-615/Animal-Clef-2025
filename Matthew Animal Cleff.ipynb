{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torchvision.models.vision_transformer import vit_b_16, ViT_B_16_Weights\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from animal_dataset import AnimalCLEFDataset  # now importable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10e51d990>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================\n",
    "# Configurations\n",
    "# =============================\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "IMAGE_SIZE = 224\n",
    "LR = 1e-4\n",
    "\n",
    "epoch = 30\n",
    "EPOCHS_CLP = epoch\n",
    "EPOCHS_PLF = epoch\n",
    "\n",
    "LAMBDA = 0.2\n",
    "ALPHA_CL = .2\n",
    "ALPHA_REC = 1.8\n",
    "\n",
    "FORCE_TRAIN_RESTART = True\n",
    "\n",
    "#DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "CHECKPOINT_DIR = './checkpoints'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "root = '../animal-clef-2025_data'\n",
    "\n",
    "# reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Set device, Mac, GPU, or CPU\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# =============================\n",
    "# Dataset\n",
    "# =============================\n",
    "class AnimalCLEFDataset(Dataset):\n",
    "    def __init__(self, root, split=\"database\", transform=None):\n",
    "        self.root = root.rstrip('/')\n",
    "        meta = pd.read_csv(f\"{self.root}/metadata.csv\")\n",
    "        sel = meta[meta['path'].str.contains(f\"/{split}/\")].reset_index(drop=True)\n",
    "        if sel.empty:\n",
    "            raise ValueError(f\"No entries for split '{split}'\")\n",
    "\n",
    "        self.paths = sel['path'].tolist()\n",
    "        self.image_ids = sel['image_id'].tolist()\n",
    "\n",
    "        if split == 'database':\n",
    "            #  Use individual identity,  \n",
    "            ids = sel['identity'].astype(str)\n",
    "\n",
    "            #  Build mapping from identity string → label index\n",
    "            self.id2idx = {iid: i for i, iid in enumerate(sorted(ids.unique()))}\n",
    "\n",
    "            #  Map each sample's identity to its label\n",
    "            self.labels = ids.map(self.id2idx).tolist()\n",
    "\n",
    "            # Safety check\n",
    "            num_classes = len(self.id2idx)\n",
    "            assert all(0 <= label < num_classes for label in self.labels), \"Invalid labels found\"\n",
    "        else:\n",
    "            self.labels = [-1] * len(sel)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img = Image.open(f\"{self.root}/{self.paths[i]}\").convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, self.labels[i]\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# MAE Encoder + Projection Head + Decoder\n",
    "# =============================\n",
    "class MAEFramework(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_dim: int = 768,\n",
    "                 proj_dim: int = 256,\n",
    "                 decoder_dim: int = 256,\n",
    "                 layer_indices: list[int] = [3, 6, 9]):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        # 1) Backbone ViT\n",
    "        self.encoder = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "        self.encoder.head = nn.Identity()\n",
    "        self.layer_indices = set(layer_indices)\n",
    "\n",
    "        # 3) Projection head\n",
    "        self.proj_head = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(embed_dim, proj_dim),\n",
    "        )\n",
    "        # 4) Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(embed_dim, decoder_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(decoder_dim, 3 * IMAGE_SIZE * IMAGE_SIZE),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, return_feats: bool = False):\n",
    "        B = x.size(0)\n",
    "        # patch embed\n",
    "        x_p = self.encoder.conv_proj(x)\n",
    "        x_p = x_p.flatten(2).transpose(1, 2)\n",
    "        cls_tok = self.encoder.class_token.expand(B, -1, -1)\n",
    "        tokens = torch.cat([cls_tok, x_p], dim=1)\n",
    "        tokens = tokens + self.encoder.encoder.pos_embedding\n",
    "\n",
    "        feats = []\n",
    "        for idx, block in enumerate(self.encoder.encoder.layers):\n",
    "            tokens = block(tokens)\n",
    "            if idx in self.layer_indices:\n",
    "                feats.append(tokens.clone())\n",
    "\n",
    "        cls_feat = self.encoder.encoder.ln(tokens[:, 0])\n",
    "        proj = self.proj_head(cls_feat)\n",
    "        rec = self.decoder(cls_feat).view(B, 3, IMAGE_SIZE, IMAGE_SIZE)\n",
    "        rec_loss = F.mse_loss(rec, x, reduction='none').mean([1, 2, 3])\n",
    "\n",
    "        if return_feats:\n",
    "            return cls_feat, proj, rec_loss, rec, feats\n",
    "        return proj, rec_loss, rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Losses\n",
    "# =============================\n",
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super().__init__()\n",
    "        self.temp = temperature\n",
    "\n",
    "    def forward(self, p1, p2, labels=None):\n",
    "        # NT-Xent instance-level contrastive loss\n",
    "        z = torch.cat([p1, p2], dim=0)\n",
    "        z = F.normalize(z, dim=1)\n",
    "        N = p1.size(0)\n",
    "        sim = torch.matmul(z, z.T) / self.temp\n",
    "        mask = torch.eye(2*N, device=sim.device).bool()\n",
    "        sim.masked_fill_(mask, -9e15)\n",
    "        idx = torch.arange(N, device=sim.device)\n",
    "        targets = torch.cat([idx + N, idx])\n",
    "        return F.cross_entropy(sim, targets)\n",
    "\n",
    "class ProtoLoss(nn.Module):\n",
    "    def forward(self, feats, prototypes, labels):\n",
    "        dist = torch.cdist(feats, prototypes)\n",
    "        return F.cross_entropy(-dist, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Utilities\n",
    "# =============================\n",
    "def compute_layer_distances(bef_feats, aft_feats, temperature=0.5):\n",
    "    total = []  # Initialize as a list to store distances per layer\n",
    "    for b, a in zip(bef_feats, aft_feats):\n",
    "        b_f, a_f = b.flatten(1), a.flatten(1)\n",
    "        eu = F.pairwise_distance(b_f, a_f)\n",
    "        cos = 1 - F.cosine_similarity(b_f, a_f, dim=1)\n",
    "        score = eu + temperature * cos  # this score is already (B,)\n",
    "        total.append(score)  # Add the current batch's score to the list\n",
    "    return torch.stack(total, dim=0).mean(dim=0)  # Stack and compute mean along dim=0\n",
    "\n",
    "def calculate_unknown_score(feat_bef, feat_aft, feat_vec, prototypes, lamda=1.0):\n",
    "    # 1. Compute multilayer feature distance (s_total)\n",
    "    s_total = compute_layer_distances(feat_bef, feat_aft, temperature=0.5)  # Can keep temp fixed or expose as param\n",
    "\n",
    "    # 2. Compute max prototype similarity (s_prototypes)\n",
    "    fv_n = F.normalize(feat_vec, dim=1)  # (B, D)\n",
    "    p_n = F.normalize(prototypes, dim=1)  # (C, D)\n",
    "    sim = torch.matmul(fv_n, p_n.T)  # (B, C)\n",
    "    s_proto, _ = sim.max(dim=1)  # (B,)\n",
    "\n",
    "    # 3. Final score using lambda\n",
    "    score = s_proto - lamda * s_total\n",
    "\n",
    "    return score  # (B,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CLP(model, loader, epochs, lr, ckpt, alpha_cl=1.0, alpha_rec=1.0, force_restart = False):\n",
    "    cl_hist, rec_hist, tot_hist = [], [], []\n",
    "    path = os.path.join(CHECKPOINT_DIR, ckpt)\n",
    "    opt  = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    start = 0\n",
    "\n",
    "    if os.path.exists(path) and force_restart:\n",
    "        print(f\"Checkpoint {path} exists. Restarting training.\")\n",
    "        os.remove(path)\n",
    "\n",
    "    # load checkpoint (stripping \"module.\" if needed) …\n",
    "    if os.path.exists(path):\n",
    "        ck     = torch.load(path, map_location=DEVICE)\n",
    "        raw_sd = ck['model']\n",
    "        sd     = {k.replace(\"module.\", \"\"): v for k, v in raw_sd.items()}\n",
    "        model.load_state_dict(sd)\n",
    "        opt.load_state_dict(ck['opt'])\n",
    "        start = ck['ep'] + 1\n",
    "\n",
    "    scl = SupConLoss()\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    for ep in range(start, epochs):\n",
    "        model.train()\n",
    "\n",
    "        # reset accumulators each epoch\n",
    "        total_cl, total_rec, total = 0.0, 0.0, 0.0\n",
    "\n",
    "        for x, y in tqdm(loader, desc=f\"CLP Ep{ep+1}\"):\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            x1 = x + 0.05 * torch.randn_like(x)\n",
    "            x2 = x + 0.05 * torch.randn_like(x)\n",
    "\n",
    "            _, p1, r1_loss, _, _ = model(x1, return_feats=True)\n",
    "            _, p2, r2_loss, _, _ = model(x2, return_feats=True)\n",
    "\n",
    "            l_cl  = scl(p1, p2)\n",
    "            l_rec = r1_loss.mean() + r2_loss.mean()\n",
    "            loss  = alpha_cl * l_cl + alpha_rec * l_rec\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total      += loss.item()\n",
    "            total_cl   += l_cl.item()\n",
    "            total_rec  += l_rec.item()\n",
    "\n",
    "        # save checkpoint\n",
    "        torch.save({\n",
    "            'model': model.module.state_dict() if isinstance(model, nn.DataParallel)\n",
    "                                                 else model.state_dict(),\n",
    "            'opt':   opt.state_dict(),\n",
    "            'ep':    ep\n",
    "        }, path)\n",
    "\n",
    "        # compute per-epoch averages\n",
    "        avg_cl  = total_cl  / len(loader)\n",
    "        avg_rec = total_rec / len(loader)\n",
    "        avg_tot = total  / len(loader)\n",
    "\n",
    "        # record histories\n",
    "        cl_hist.append(avg_cl)\n",
    "        rec_hist.append(avg_rec)\n",
    "        tot_hist.append(avg_tot)\n",
    "\n",
    "        print(f\"CLP Epoch {ep+1}: total={avg_tot:.4f}, cl={avg_cl:.4f}, rec={avg_rec:.4f}\")\n",
    "\n",
    "    return model, cl_hist, rec_hist, tot_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def train_CLP(model, loader, epochs, lr, ckpt, alpha_cl=1.0, alpha_rec=1.0):\n",
    "    \n",
    "    path = os.path.join(CHECKPOINT_DIR, ckpt)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    start = 0\n",
    "\n",
    "    # --- load checkpoint if it exists, stripping \"module.\" if necessary\n",
    "    if os.path.exists(path):\n",
    "        ck = torch.load(path, map_location=DEVICE)\n",
    "        raw_sd = ck['model']\n",
    "        # strip DataParallel \"module.\" prefix\n",
    "        sd = {k.replace(\"module.\", \"\"): v for k, v in raw_sd.items()}\n",
    "        model.load_state_dict(sd)\n",
    "        opt.load_state_dict(ck['opt'])\n",
    "        start = ck['ep'] + 1\n",
    "    # ---------------------------------------------------------------\n",
    "\n",
    "    scl = SupConLoss()\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    for ep in range(start, epochs):\n",
    "        model.train()\n",
    "        total = 0.0\n",
    "        for x, y in tqdm(loader, desc=f\"CLP Ep{ep+1}\"):\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            x1 = x + 0.05 * torch.randn_like(x)\n",
    "            x2 = x + 0.05 * torch.randn_like(x)\n",
    "            f1, p1, r1_loss, r1, _ = model(x1, return_feats=True)\n",
    "            f2, p2, r2_loss, r2, _ = model(x2, return_feats=True)\n",
    "            l_cl  = scl(p1, p2)\n",
    "            l_rec = r1_loss.mean() + r2_loss.mean()\n",
    "            loss  = alpha_cl * l_cl + alpha_rec * l_rec\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total += loss.item()\n",
    "\n",
    "        torch.save({\n",
    "            'model': model.state_dict() if not isinstance(model, nn.DataParallel)\n",
    "                              else model.module.state_dict(),\n",
    "            'opt':   opt.state_dict(),\n",
    "            'ep':    ep\n",
    "        }, path)\n",
    "        print(f\"CLP Epoch {ep+1}: {total/len(loader):.4f}\")\n",
    "        \"\"\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_PLF(model, loader, epochs, lr, ckpt, num_classes, encoder_pre):\n",
    "    path = os.path.join(CHECKPOINT_DIR, ckpt)\n",
    "    # unwrap if DataParallel\n",
    "    base_model = model.module if isinstance(model, nn.DataParallel) else model\n",
    "    embed_dim   = base_model.embed_dim\n",
    "\n",
    "    proto_tensor = torch.randn(num_classes, embed_dim, device=DEVICE)\n",
    "    proto = nn.Parameter(proto_tensor, requires_grad=True)\n",
    "    opt   = torch.optim.Adam(list(model.parameters()) + [proto], lr=lr)\n",
    "    start = 0\n",
    "\n",
    "    # --- load checkpoint if it exists, stripping \"module.\" if necessary\n",
    "    if os.path.exists(path):\n",
    "        ck = torch.load(path, map_location=DEVICE)\n",
    "        raw_sd = ck['model']\n",
    "        sd = {k.replace(\"module.\", \"\"): v for k, v in raw_sd.items()}\n",
    "        model.load_state_dict(sd)\n",
    "        proto.data = ck['proto']\n",
    "        opt.load_state_dict(ck['opt'])\n",
    "        start = ck['ep'] + 1\n",
    "    # ---------------------------------------------------------------\n",
    "\n",
    "    ploss = ProtoLoss()\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    for ep in range(start, epochs):\n",
    "        model.train()\n",
    "        total = 0.0\n",
    "        for x, y in tqdm(loader, desc=f\"PLF Ep{ep+1}\"):\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            feats, _, _, _, _ = model(x, return_feats=True)\n",
    "            loss = ploss(feats, proto, y)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total += loss.item()\n",
    "\n",
    "        torch.save({\n",
    "            'model': model.state_dict() if not isinstance(model, nn.DataParallel)\n",
    "                              else model.module.state_dict(),\n",
    "            'proto': proto.data,\n",
    "            'opt':   opt.state_dict(),\n",
    "            'ep':    ep\n",
    "        }, path)\n",
    "        print(f\"PLF Epoch {ep+1}: {total/len(loader):.4f}\")\n",
    "\n",
    "    return proto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# =============================\n",
    "# Training: CLP\n",
    "# =============================\n",
    "def train_CLP(model, loader, epochs, lr, ckpt, alpha_cl=1.0, alpha_rec=1.0):\n",
    "    path = os.path.join(CHECKPOINT_DIR, ckpt)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    start = 0\n",
    "    if os.path.exists(path):\n",
    "        ck = torch.load(path)\n",
    "        model.load_state_dict(ck['model'])\n",
    "        opt.load_state_dict(ck['opt'])\n",
    "        start = ck['ep'] + 1\n",
    "    scl = SupConLoss()\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    for ep in range(start, epochs):\n",
    "        model.train()\n",
    "        total = 0.0\n",
    "        for x, y in tqdm(loader, desc=f\"CLP Ep{ep+1}\"):\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            x1 = x + 0.05 * torch.randn_like(x)\n",
    "            x2 = x + 0.05 * torch.randn_like(x)\n",
    "            f1, p1, r1_loss, r1, _ = model(x1, return_feats=True)\n",
    "            f2, p2, r2_loss, r2, _ = model(x2, return_feats=True)\n",
    "            l_cl = scl(p1, p2)\n",
    "            l_rec = r1_loss.mean() + r2_loss.mean()\n",
    "            loss = alpha_cl * l_cl + alpha_rec * l_rec\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total += loss.item()\n",
    "        torch.save({'model': model.state_dict(), 'opt': opt.state_dict(), 'ep': ep}, path)\n",
    "        print(f\"CLP Epoch {ep+1}: {total/len(loader):.4f}\")\n",
    "\n",
    "\n",
    "# =============================\n",
    "# Training: PLF\n",
    "# =============================\n",
    "def train_PLF(model, loader, epochs, lr, ckpt, num_classes, encoder_pre):\n",
    "    path = os.path.join(CHECKPOINT_DIR, ckpt)\n",
    "    # unwrap if DataParallel\n",
    "    base_model = model.module if isinstance(model, nn.DataParallel) else model\n",
    "    embed_dim = base_model.embed_dim\n",
    "    proto_tensor = torch.randn(num_classes, embed_dim, device=DEVICE)\n",
    "    proto = nn.Parameter(proto_tensor, requires_grad=True)\n",
    "    opt = torch.optim.Adam(list(model.parameters()) + [proto], lr=lr)\n",
    "    start = 0\n",
    "    if os.path.exists(path):\n",
    "        ck = torch.load(path)\n",
    "        model.load_state_dict(ck['model'])\n",
    "        proto.data = ck['proto']\n",
    "        opt.load_state_dict(ck['opt'])\n",
    "        start = ck['ep'] + 1\n",
    "    ploss = ProtoLoss()\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    for ep in range(start, epochs):\n",
    "        model.train()\n",
    "        total = 0.0\n",
    "        for x, y in tqdm(loader, desc=f\"PLF Ep{ep+1}\"):\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            feats, _, _, _, _ = model(x, return_feats=True)\n",
    "            loss = ploss(feats, proto, y)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total += loss.item()\n",
    "        torch.save({'model': model.state_dict(), 'proto': proto.data, 'opt': opt.state_dict(), 'ep': ep}, path)\n",
    "        print(f\"PLF Epoch {ep+1}: {total/len(loader):.4f}\")\n",
    "    return proto\n",
    "\"\"\";\n",
    "    \n",
    "# =============================\n",
    "# Inference\n",
    "# =============================\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(enc_pre, model, proto, loader, threshold, lamda=1.0):\n",
    "    enc_pre.eval()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    for x, _ in tqdm(loader, desc=\"Infer\"):\n",
    "        x = x.to(DEVICE)\n",
    "        enc_pre = enc_pre.to(DEVICE)\n",
    "        model = model.to(DEVICE)\n",
    "\n",
    "        _, _, _, _, bef_feats = enc_pre(x, return_feats=True)\n",
    "        feat, _, _, _, aft_feats = model(x, return_feats=True)\n",
    "\n",
    "        # 1. Calculate unknown score\n",
    "        scores = calculate_unknown_score(bef_feats, aft_feats, feat, proto, lamda = lamda)  # shape: (B,)\n",
    "\n",
    "        # 2. Predict the most similar known class\n",
    "        idx = torch.argmax(torch.matmul(F.normalize(feat, dim=1), F.normalize(proto, dim=1).T), dim=1)  # (B,)\n",
    "\n",
    "        # 3. Threshold to filter unknowns\n",
    "        known = scores > threshold\n",
    "        pred = idx.clone()\n",
    "        pred[~known] = -1  # mark unknowns\n",
    "\n",
    "        preds.append(pred.cpu())\n",
    "\n",
    "    return torch.cat(preds, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Submission\n",
    "# =============================\n",
    "def generate_submission(root, preds, db_ds):\n",
    "    sub = pd.read_csv(f\"{root}/sample_submission.csv\")\n",
    "    meta = pd.read_csv(f\"{root}/metadata.csv\")\n",
    "    q = meta[meta['path'].str.contains('/query/')].reset_index(drop=True)\n",
    "    q['pred_idx'] = preds.numpy()\n",
    "\n",
    "    # Step 1: Print raw predicted indices\n",
    "    print(\"\\nRaw predicted indices (pred_idx):\")\n",
    "    print(q[['image_id', 'pred_idx']].head(10))\n",
    "\n",
    "    # Step 2: Index to identity mapping\n",
    "    idx2id = {v: k for k, v in db_ds.id2idx.items()}\n",
    "    q['prediction'] = q['pred_idx'].apply(lambda i: 'new_individual' if i < 0 else idx2id.get(int(i), f\"unknown_{i}\"))\n",
    "\n",
    "    # Step 3: Print mapped predictions\n",
    "    print(\"\\nMapped predictions (after idx2id):\")\n",
    "    print(q[['image_id', 'prediction']].head(10))\n",
    "\n",
    "    # drop the original metadata identity so we don't end up with two columns\n",
    "    q = q.drop(columns=['identity'])\n",
    "\n",
    "    # rename 'prediction' → 'identity' so the output column is called identity\n",
    "    q = q.rename(columns={'prediction':'identity'})\n",
    "\n",
    "    # now merge on image_id and keep the 'identity' column\n",
    "    out = sub[['image_id']].merge(q[['image_id','identity']], on='image_id')\n",
    "\n",
    "    #out = sub[['image_id']].merge(q[['image_id', 'identity']], on='image_id')\n",
    "    #out = sub[['image_id']].merge(q[['image_id','prediction']], on='image_id')\n",
    "\n",
    "\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    save_path = f'submission_{timestamp}.csv'\n",
    "    out.to_csv(save_path, index=False)\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint ./checkpoints/clp.pth exists. Restarting training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep1:   0%|          | 0/409 [00:00<?, ?it/s]/Users/matthewjones2/anaconda3/envs/574_animal_clef_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "CLP Ep1: 100%|██████████| 409/409 [08:26<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 1: total=0.6409, cl=2.3755, rec=0.0921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep2: 100%|██████████| 409/409 [08:32<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 2: total=0.5667, cl=2.3089, rec=0.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep3: 100%|██████████| 409/409 [08:29<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 3: total=0.5517, cl=2.2947, rec=0.0516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep4: 100%|██████████| 409/409 [08:34<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 4: total=0.5411, cl=2.2879, rec=0.0464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep5: 100%|██████████| 409/409 [08:35<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 5: total=0.5339, cl=2.2811, rec=0.0432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep6: 100%|██████████| 409/409 [08:28<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 6: total=0.5292, cl=2.2765, rec=0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep7: 100%|██████████| 409/409 [08:33<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 7: total=0.5268, cl=2.2739, rec=0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep8: 100%|██████████| 409/409 [08:31<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 8: total=0.5249, cl=2.2732, rec=0.0390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep9: 100%|██████████| 409/409 [08:29<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 9: total=0.5223, cl=2.2712, rec=0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep10: 100%|██████████| 409/409 [08:28<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 10: total=0.5207, cl=2.2711, rec=0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep11: 100%|██████████| 409/409 [08:27<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 11: total=0.5195, cl=2.2708, rec=0.0363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep12: 100%|██████████| 409/409 [08:27<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 12: total=0.5174, cl=2.2685, rec=0.0354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep13: 100%|██████████| 409/409 [08:27<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 13: total=0.5157, cl=2.2666, rec=0.0347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep14: 100%|██████████| 409/409 [08:26<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 14: total=0.5147, cl=2.2675, rec=0.0340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep15: 100%|██████████| 409/409 [08:26<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 15: total=0.5135, cl=2.2665, rec=0.0335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep16: 100%|██████████| 409/409 [08:26<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 16: total=0.5126, cl=2.2661, rec=0.0330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep17: 100%|██████████| 409/409 [08:20<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 17: total=0.5116, cl=2.2650, rec=0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep18: 100%|██████████| 409/409 [08:21<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 18: total=0.5106, cl=2.2639, rec=0.0321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep19: 100%|██████████| 409/409 [08:21<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 19: total=0.5098, cl=2.2636, rec=0.0317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep20: 100%|██████████| 409/409 [08:22<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 20: total=0.5091, cl=2.2638, rec=0.0313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep21: 100%|██████████| 409/409 [08:26<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 21: total=0.5086, cl=2.2635, rec=0.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep22: 100%|██████████| 409/409 [08:27<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 22: total=0.5076, cl=2.2624, rec=0.0306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep23: 100%|██████████| 409/409 [08:25<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 23: total=0.5072, cl=2.2631, rec=0.0303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep24: 100%|██████████| 409/409 [08:19<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 24: total=0.5061, cl=2.2607, rec=0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep25: 100%|██████████| 409/409 [08:20<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 25: total=0.5057, cl=2.2617, rec=0.0296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep26: 100%|██████████| 409/409 [08:22<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 26: total=0.5051, cl=2.2615, rec=0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep27: 100%|██████████| 409/409 [08:23<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 27: total=0.5043, cl=2.2605, rec=0.0290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep28: 100%|██████████| 409/409 [08:22<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 28: total=0.5039, cl=2.2604, rec=0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep29: 100%|██████████| 409/409 [08:22<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 29: total=0.5033, cl=2.2600, rec=0.0285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLP Ep30: 100%|██████████| 409/409 [08:22<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLP Epoch 30: total=0.5030, cl=2.2602, rec=0.0283\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prototype shape: torch.Size([1102, 768])\n",
      "Number of unique classes: 1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer: 100%|██████████| 67/67 [00:48<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission…\n",
      "\n",
      "Raw predicted indices (pred_idx):\n",
      "   image_id  pred_idx\n",
      "0         3        -1\n",
      "1         5        24\n",
      "2        12        -1\n",
      "3        13        -1\n",
      "4        18        -1\n",
      "5        19        -1\n",
      "6        27        -1\n",
      "7        33        -1\n",
      "8        36        -1\n",
      "9        45        -1\n",
      "\n",
      "Mapped predictions (after idx2id):\n",
      "   image_id          prediction\n",
      "0         3      new_individual\n",
      "1         5  LynxID2025_lynx_32\n",
      "2        12      new_individual\n",
      "3        13      new_individual\n",
      "4        18      new_individual\n",
      "5        19      new_individual\n",
      "6        27      new_individual\n",
      "7        33      new_individual\n",
      "8        36      new_individual\n",
      "9        45      new_individual\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# Main Workflow\n",
    "# =============================\n",
    "def main():\n",
    "    #root = '/kaggle/input/animal-clef-2025'\n",
    "    tf = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    #idx2id = {v: k for k, v in db_ds.id2idx.items()}\n",
    "\n",
    "    db_ds = AnimalCLEFDataset(root, 'database', transform=tf)\n",
    "    \n",
    "    #print(\"Example metadata path[0]:\", db_ds.paths[0])\n",
    "    #print(\"Looking for file at:\", os.path.join(db_ds.root, db_ds.paths[0]))\n",
    "    #print(\"Exists on disk?\", os.path.exists(os.path.join(db_ds.root, db_ds.paths[0])))\n",
    "    \n",
    "    db_loader = DataLoader(db_ds, batch_size = BATCH_SIZE, shuffle=True,\n",
    "                           num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    query_ds = AnimalCLEFDataset(root, 'query', transform=tf)\n",
    "    q_loader = DataLoader(query_ds, batch_size = BATCH_SIZE, shuffle=False,\n",
    "                           num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    clp_model = MAEFramework()\n",
    "    plf_model = MAEFramework()\n",
    "\n",
    "    # pick your device\n",
    "    if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        DEVICE = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        DEVICE = torch.device(\"cuda\")\n",
    "    else:\n",
    "        DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "    # decide which GPUs to wrap\n",
    "    cuda_gpus = torch.cuda.device_count()\n",
    "    if DEVICE.type == \"cuda\" and cuda_gpus > 1:\n",
    "        device_ids = list(range(cuda_gpus))  # e.g. [0,1,…]\n",
    "        clp_model = nn.DataParallel(clp_model,  device_ids=device_ids).to(DEVICE)\n",
    "        plf_model = nn.DataParallel(plf_model,  device_ids=device_ids).to(DEVICE)\n",
    "    else:\n",
    "        # single‐device: MPS, single CUDA, or CPU\n",
    "        clp_model = clp_model.to(DEVICE)\n",
    "        plf_model = plf_model.to(DEVICE)\n",
    "\n",
    "    # now training and inference will work on either MPS or CUDA\n",
    "    #train_CLP(clp_model, db_loader, EPOCHS_CLP, LR,  'clp.pth', alpha_cl = ALPHA_CL, alpha_rec = ALPHA_REC)\n",
    "    \n",
    "    clp_model, cl_hist, rec_hist, tot_hist = train_CLP(\n",
    "        clp_model, db_loader, EPOCHS_CLP, LR, 'clp.pth',\n",
    "        alpha_cl=ALPHA_CL, alpha_rec=ALPHA_REC, force_restart=FORCE_TRAIN_RESTART)\n",
    "    \n",
    "    epochs = list(range(1, len(cl_hist)+1))\n",
    "    plt.plot(epochs, cl_hist, label='Contrastive Loss')\n",
    "    plt.plot(epochs, rec_hist, label='Reconstruction Loss')\n",
    "    plt.plot(epochs, tot_hist, label='Total Loss')\n",
    "\n",
    "    plt.title(f'CLP Losses (α_cl={ALPHA_CL}, α_rec={ALPHA_REC}, λ={LAMBDA}, batch={BATCH_SIZE})')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    prototype = train_PLF(plf_model, db_loader, EPOCHS_PLF, LR,\n",
    "                          'plf.pth', len(db_ds.id2idx), clp_model)\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"Prototype shape:\", prototype.shape)\n",
    "    print(\"Number of unique classes:\", len(db_ds.id2idx))\n",
    "\n",
    "    # Plot the score distribution before estimating threshold\n",
    "    #plot_score_distribution(clp_model, plf_model, prototype, db_loader)\n",
    "\n",
    "    # Estimate threshold from database distribution\n",
    "    dists = []\n",
    "    with torch.no_grad():\n",
    "        for x, _ in DataLoader(db_ds, batch_size = BATCH_SIZE, shuffle=False,\n",
    "                               num_workers=NUM_WORKERS, pin_memory=True):\n",
    "            x = x.to(DEVICE)\n",
    "            feat, _, _, _, aft_feats = plf_model(x, return_feats=True)\n",
    "            _, _, _, _, bef_feats = clp_model(x, return_feats=True)\n",
    "            scores = calculate_unknown_score(bef_feats, aft_feats, feat, prototype, lamda = LAMBDA)\n",
    "            dists.extend(scores.cpu().tolist())\n",
    "\n",
    "\n",
    "    threshold = torch.quantile(torch.tensor(dists), 0.95).item()\n",
    "\n",
    "\n",
    "    # Inference on query set\n",
    "    with torch.no_grad():\n",
    "        #lamda = 0.2 # or any value you want to test\n",
    "        preds = inference(clp_model, plf_model, prototype, q_loader, threshold, lamda = LAMBDA)\n",
    "\n",
    "\n",
    "    print(\"Saving submission…\")\n",
    "    generate_submission(root, preds, db_ds)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = inference(clp_model, plf_model, prototype, q_loader, threshold, lamda=lamda)\n",
    "#print(\"Saving submission…\")\n",
    "#generate_submission(root, preds, db_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-09T03:44:13.919371Z",
     "iopub.status.busy": "2025-05-09T03:44:13.918842Z",
     "iopub.status.idle": "2025-05-09T04:18:59.475615Z",
     "shell.execute_reply": "2025-05-09T04:18:59.474736Z",
     "shell.execute_reply.started": "2025-05-09T03:44:13.919346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11223220,
     "sourceId": 91451,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "574_animal_clef_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
