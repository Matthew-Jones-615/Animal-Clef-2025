{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZAyziMzYgQq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define model based on vit-base from the code.\n",
        "model = MaskedAutoencoderViT(\n",
        "    img_size=224, patch_size=16, in_chans=3,\n",
        "    embed_dim=768, depth=12, num_heads=12,\n",
        "    decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16,\n",
        "    mlp_ratio=4.\n",
        ").to(device)\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/MAE_demo/MAE_demo/mae/mae_pretrain_vit_base.pth\" # change path\n",
        "\n",
        "ckpt = torch.load(checkpoint_path, map_location=device)\n",
        "model.load_state_dict(ckpt[\"model\"], strict=False)\n",
        "model.eval()\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "cw6Fmx8zYn8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class AnimalCLEFDataset(Dataset):\n",
        "    def __init__(self, root, split=\"database\", transform=None):\n",
        "        self.root = root.rstrip('/') # Remove trailing slash if present\n",
        "        meta = pd.read_csv(f\"/content/drive/MyDrive/animalclef2025/metadata.csv\")\n",
        "        sel = meta[meta['path'].str.contains(f\"/{split}/\")].reset_index(drop=True)\n",
        "        if sel.empty:\n",
        "            raise ValueError(f\"No entries for split '{split}'\")\n",
        "\n",
        "        self.paths = sel['path'].tolist()\n",
        "        self.image_ids = sel['image_id'].tolist()\n",
        "\n",
        "        if split == 'database':\n",
        "            #  Use individual identity,\n",
        "            ids = sel['identity'].astype(str)\n",
        "\n",
        "            #  Build mapping from identity string â†’ label index\n",
        "            self.id2idx = {iid: i for i, iid in enumerate(sorted(ids.unique()))}\n",
        "\n",
        "            #  Map each sample's identity to its label\n",
        "            self.labels = ids.map(self.id2idx).tolist()\n",
        "\n",
        "            # Safety check\n",
        "            num_classes = len(self.id2idx)\n",
        "            assert all(0 <= label < num_classes for label in self.labels), \"Invalid labels found\"\n",
        "        else:\n",
        "            self.labels = [-1] * len(sel)\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # Fix: Remove .lstrip('/') to avoid removing necessary part of the path\n",
        "        img_path = os.path.join(self.root, self.paths[i])\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.labels[i]\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "K30BgSKKY2M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model_and_checkpoint(model, epoch, optimizer, loss, save_path):\n",
        "    \"\"\"Saves the model and checkpoint to the specified path.\"\"\"\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "    }\n",
        "    torch.save(checkpoint, save_path)\n",
        "    print(f\"Model and checkpoint saved to: {save_path}\")\n"
      ],
      "metadata": {
        "id": "uAn9x9NTY8L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, embed_dim=768, hidden_dim=256, num_classes=10, dropout_prob=0.5):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_prob),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        cls_token = x[:, 0]\n",
        "        logits = self.net(cls_token)\n",
        "        probs = self.softmax(logits)\n",
        "        return logits, probs\n",
        "\n",
        "class MAE_Classifier(nn.Module):\n",
        "    def __init__(self, mae_model, num_classes=10, freeze_encoder=True):\n",
        "        super().__init__()\n",
        "        # load mae model\n",
        "        self.encoder = mae_model.to(device)\n",
        "        if freeze_encoder:\n",
        "            for p in self.encoder.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        # get embedding dim dynamically\n",
        "        embed_dim = self.encoder.patch_embed.proj.out_channels\n",
        "        # classification head\n",
        "        self.head = ClassificationHead(embed_dim=embed_dim, num_classes=num_classes).to(device)\n",
        "        # Store class-wise probabilities\n",
        "        self.class_probs = defaultdict(list)\n",
        "        self.class_thresholds = {}\n",
        "\n",
        "    def forward(self, img):\n",
        "        img = img.to(device)\n",
        "        enc_out = self.encoder.forward_encoder(img, mask_ratio=0.0)[0]\n",
        "        logits, probs = self.head(enc_out)\n",
        "        return logits, probs\n",
        "\n",
        "    def collect_train_probs(self, train_loader):\n",
        "        \"\"\"Collect probabilities for each class during training\"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, labels in train_loader:\n",
        "                _, probs = self.forward(images)\n",
        "                probs = probs.cpu().numpy()\n",
        "                for i in range(len(labels)):\n",
        "                    self.class_probs[labels[i].item()].append(probs[i])\n",
        "\n",
        "        # Calculate mean probabilities and thresholds for each class\n",
        "        for class_id in self.class_probs:\n",
        "            class_probs = np.array(self.class_probs[class_id])\n",
        "            mean_probs = np.mean(class_probs, axis=0)\n",
        "            self.class_probs[class_id] = mean_probs\n",
        "            # Threshold is the highest probability value for this class\n",
        "            self.class_thresholds[class_id] = np.max(mean_probs)\n",
        "\n",
        "    def train_classifier(self, train_loader, val_loader, epochs=40, lr=1e-3):\n",
        "        \"\"\"Train the classification head with train/val split and log loss/acc\"\"\"\n",
        "        self.train()\n",
        "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "        optimizer = optim.AdamW(self.head.parameters(), lr=lr,  weight_decay=5e-4)\n",
        "\n",
        "        train_losses, val_losses = [], []\n",
        "        train_accuracies, val_accuracies = [], []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            running_loss = 0.0\n",
        "            correct, total = 0, 0\n",
        "\n",
        "            for images, labels in train_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                logits, _ = self.forward(images)\n",
        "                loss = criterion(logits, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                _, predicted = torch.max(logits, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            train_loss = running_loss / len(train_loader)\n",
        "            train_acc = 100 * correct / total\n",
        "            train_losses.append(train_loss)\n",
        "            train_accuracies.append(train_acc)\n",
        "\n",
        "            # Validation\n",
        "            self.eval()\n",
        "            val_loss = 0.0\n",
        "            val_correct, val_total = 0, 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    logits, _ = self.forward(images)\n",
        "                    loss = criterion(logits, labels)\n",
        "                    val_loss += loss.item()\n",
        "                    _, predicted = torch.max(logits, 1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            val_acc = 100 * val_correct / val_total\n",
        "            val_losses.append(val_loss)\n",
        "            val_accuracies.append(val_acc)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs} \"\n",
        "                  f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% \"\n",
        "                  f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        # Plot loss curves\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(train_losses, label='Train Loss')\n",
        "        plt.plot(val_losses, label='Validation Loss')\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Training vs Validation Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def predict_with_openmax(self, test_loader):\n",
        "        \"\"\"Predict using OpenMax approach with softmax probabilities\"\"\"\n",
        "        self.eval()\n",
        "        predictions = []\n",
        "        all_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, _ in test_loader:\n",
        "                _, probs = self.forward(images)\n",
        "                batch_probs = probs.cpu().numpy()\n",
        "                all_probs.extend(batch_probs)\n",
        "\n",
        "                for prob in batch_probs:\n",
        "                    min_dist = float('inf')\n",
        "                    predicted_class = None\n",
        "\n",
        "                    # Compare with each known class\n",
        "                    for class_id, class_mean_probs in self.class_probs.items():\n",
        "                        dist = np.linalg.norm(prob - class_mean_probs)\n",
        "                        if dist < min_dist:\n",
        "                            min_dist = dist\n",
        "                            predicted_class = class_id\n",
        "\n",
        "                    # Check if any probability exceeds the max seen in training\n",
        "                    max_train_prob = max(self.class_thresholds.values())\n",
        "                    margin = 0.05  # Reduced from 0.1 to 0.05\n",
        "                    if np.max(prob) > max_train_prob + margin:\n",
        "                        predicted_class = \"new_individual\"\n",
        "\n",
        "                    predictions.append(predicted_class)\n",
        "\n",
        "        return predictions, np.array(all_probs)"
      ],
      "metadata": {
        "id": "FWa8EnvvZFys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample_submission(dataset_query, predictions, id2identity, file_name='/content/drive/MyDrive/MAE_demo/sample_submission.csv'):\n",
        "    # Map numeric predictions back to original identity strings\n",
        "    mapped_predictions = []\n",
        "    for pred in predictions:\n",
        "        if pred == \"new_individual\":\n",
        "            mapped_predictions.append(\"new_individual\")\n",
        "        elif pred in id2identity:  # Check if pred (label index) is in id2identity\n",
        "            mapped_predictions.append(id2identity[pred])\n",
        "        else:\n",
        "            # Handle unseen labels (e.g., assign them as 'new_individual')\n",
        "            mapped_predictions.append(\"new_individual\")\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'image_id': dataset_query.image_ids,\n",
        "        'identity': mapped_predictions\n",
        "    })\n",
        "    df.to_csv(file_name, index=False)"
      ],
      "metadata": {
        "id": "1K1lzotfZbVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Define transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Create datasets using AnimalCLEFDataset\n",
        "    #data_path = '/content/drive/MyDrive/animalclef2025'\n",
        "    images_path = '/content/drive/MyDrive/animalclef2025'\n",
        "\n",
        "    try:\n",
        "        train_dataset = AnimalCLEFDataset(images_path, split=\"database\", transform=transform)\n",
        "        test_dataset = AnimalCLEFDataset(images_path, split=\"query\", transform=transform)\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating datasets: {e}\")\n",
        "        raise\n",
        "\n",
        "    # Print dataset statistics\n",
        "    print(f\"Found {len(train_dataset)} training samples across {len(train_dataset.id2idx)} classes\")\n",
        "    print(f\"Found {len(test_dataset)} query images\")\n",
        "\n",
        "    # Create data loaders\n",
        "    # Split train dataset into train and validation\n",
        "    train_len = int(0.8 * len(train_dataset))\n",
        "    val_len = len(train_dataset) - train_len\n",
        "    train_set, val_set = torch.utils.data.random_split(train_dataset, [train_len, val_len])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_set, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "    # Initialize classifier\n",
        "    num_classes = len(train_dataset.id2idx)\n",
        "    print(f\"Number of classes: {num_classes}\")\n",
        "    classifier = MAE_Classifier(model, num_classes=num_classes, freeze_encoder=True)\n",
        "\n",
        "    # Train the classifier head\n",
        "    print(\"Training classifier head...\")\n",
        "    classifier.train_classifier(train_loader, val_loader, epochs=20, lr=1e-2)\n",
        "\n",
        "\n",
        "    # Collect training probabilities (after softmax)\n",
        "    print(\"Collecting training probabilities...\")\n",
        "    classifier.collect_train_probs(train_loader)\n",
        "\n",
        "    # Predict on test set\n",
        "    print(\"Predicting on query images...\")\n",
        "    predictions, all_probs = classifier.predict_with_openmax(test_loader)\n",
        "\n",
        "    # Reverse the id2idx mapping\n",
        "    idx2id = {v: k for k, v in train_dataset.id2idx.items()}\n",
        "\n",
        "    # Create submission file with proper identity strings\n",
        "    print(\"Creating submission file...\")\n",
        "    create_sample_submission(test_dataset, predictions, idx2id)  # Pass idx2id\n",
        "\n",
        "    print(\"\\nSubmission file created successfully!\")\n",
        "    print(\"Sample predictions:\")\n",
        "\n",
        "    # Convert predictions in sample_df to identity strings\n",
        "    sample_df = pd.DataFrame({\n",
        "        'image_id': test_dataset.image_ids[:5],\n",
        "        'identity': [idx2id.get(p, \"new_individual\") for p in predictions[:5]]  # Use idx2id for mapping\n",
        "    })\n",
        "    print(sample_df)"
      ],
      "metadata": {
        "id": "vWwc6nwgZFum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69i0CU8eZFqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JyIsJHu5ZFpJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}