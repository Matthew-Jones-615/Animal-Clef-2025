{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91451,"databundleVersionId":11223220,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 🐾 AnimalCLEF2025 Competition: Official Starter notebook\n\nThe **Goal of the** [AnimalCLEF2025](https://www.kaggle.com/competitions/animal-clef-2025/) competition is to identify individual animal (lynxes, salamanders and sea turtles) in photos. This notebook visualize the provided dataset and propose a baseline solution, based on the state-of-the-art re-identification model [MegaDescriptor](https://huggingface.co/BVRA/MegaDescriptor-L-384). The dataset is split into the database and query sets. For each image from the query set, the goal is to:\n\n- Predict whether the depicted individual is in the database.\n- If no, the prediction is `new_individual`.\n- If yes, the prediction should be the same as the individual in the database.","metadata":{}},{"cell_type":"markdown","source":"## Dependencies instalation\nFor the competition we provide two Python packages for loading and preprocessing of available datasets ([wildlife-datasets](https://github.com/WildlifeDatasets/wildlife-datasets)) and tools / method for animal re-identification ([wildlife-tools](https://github.com/WildlifeDatasets/wildlife-tools)).","metadata":{"execution":{"iopub.status.busy":"2025-02-28T16:18:13.120141Z","iopub.execute_input":"2025-02-28T16:18:13.120497Z","iopub.status.idle":"2025-02-28T16:18:13.1244Z","shell.execute_reply.started":"2025-02-28T16:18:13.120467Z","shell.execute_reply":"2025-02-28T16:18:13.12338Z"}}},{"cell_type":"code","source":"!pip install git+https://github.com/WildlifeDatasets/wildlife-datasets@develop\n!pip install git+https://github.com/WildlifeDatasets/wildlife-tools","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-02-28T19:02:09.384161Z","iopub.execute_input":"2025-02-28T19:02:09.384455Z","iopub.status.idle":"2025-02-28T19:02:48.987210Z","shell.execute_reply.started":"2025-02-28T19:02:09.384420Z","shell.execute_reply":"2025-02-28T19:02:48.986046Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/WildlifeDatasets/wildlife-datasets@develop\n  Cloning https://github.com/WildlifeDatasets/wildlife-datasets (to revision develop) to /tmp/pip-req-build-w2ekgj5y\n  Running command git clone --filter=blob:none --quiet https://github.com/WildlifeDatasets/wildlife-datasets /tmp/pip-req-build-w2ekgj5y\n  Running command git checkout -b develop --track origin/develop\n  Switched to a new branch 'develop'\n  Branch 'develop' set up to track remote branch 'develop' from 'origin'.\n  Resolved https://github.com/WildlifeDatasets/wildlife-datasets to commit 78f1705c4ab028a5608356fd63593f0dd5b2d13e\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.10/dist-packages (from wildlife-datasets==1.0.5) (1.26.4)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from wildlife-datasets==1.0.5) (2.2.2)\nRequirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.10/dist-packages (from wildlife-datasets==1.0.5) (4.67.1)\nRequirement already satisfied: opencv-python>=4.5.5.62 in /usr/local/lib/python3.10/dist-packages (from wildlife-datasets==1.0.5) (4.10.0.84)\nRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from wildlife-datasets==1.0.5) (11.0.0)\nRequirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from wildlife-datasets==1.0.5) (1.2.2)\nRequirement already satisfied: matplotlib>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from wildlife-datasets==1.0.5) (3.7.5)\nRequirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from wildlife-datasets==1.0.5) (2.0.8)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from wildlife-datasets==1.0.5) (3.2.0)\nRequirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from wildlife-datasets==1.0.5) (5.2.0)\nRequirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from wildlife-datasets==1.0.5) (1.6.17)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->wildlife-datasets==1.0.5) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->wildlife-datasets==1.0.5) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->wildlife-datasets==1.0.5) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->wildlife-datasets==1.0.5) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->wildlife-datasets==1.0.5) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->wildlife-datasets==1.0.5) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->wildlife-datasets==1.0.5) (2.8.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.4->wildlife-datasets==1.0.5) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.4->wildlife-datasets==1.0.5) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.4->wildlife-datasets==1.0.5) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.4->wildlife-datasets==1.0.5) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.4->wildlife-datasets==1.0.5) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.4->wildlife-datasets==1.0.5) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->wildlife-datasets==1.0.5) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->wildlife-datasets==1.0.5) (2024.2)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.1->wildlife-datasets==1.0.5) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.1->wildlife-datasets==1.0.5) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.1->wildlife-datasets==1.0.5) (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->wildlife-datasets==1.0.5) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->wildlife-datasets==1.0.5) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->wildlife-datasets==1.0.5) (0.3.8)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->wildlife-datasets==1.0.5) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->wildlife-datasets==1.0.5) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->wildlife-datasets==1.0.5) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->wildlife-datasets==1.0.5) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->wildlife-datasets==1.0.5) (3.11.10)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->wildlife-datasets==1.0.5) (0.27.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->wildlife-datasets==1.0.5) (6.0.2)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->wildlife-datasets==1.0.5) (4.12.3)\nRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->wildlife-datasets==1.0.5) (1.17.0)\nRequirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->wildlife-datasets==1.0.5) (2024.12.14)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->wildlife-datasets==1.0.5) (8.0.4)\nRequirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->wildlife-datasets==1.0.5) (2.2.3)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->wildlife-datasets==1.0.5) (6.2.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets==1.0.5) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets==1.0.5) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets==1.0.5) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets==1.0.5) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets==1.0.5) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets==1.0.5) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets==1.0.5) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets==1.0.5) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets->wildlife-datasets==1.0.5) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->wildlife-datasets==1.0.5) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->wildlife-datasets==1.0.5) (3.10)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->wildlife-datasets==1.0.5) (2.6)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->wildlife-datasets==1.0.5) (0.5.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.4->wildlife-datasets==1.0.5) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.4->wildlife-datasets==1.0.5) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.4->wildlife-datasets==1.0.5) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.4->wildlife-datasets==1.0.5) (2024.2.0)\nRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->wildlife-datasets==1.0.5) (1.3)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->wildlife-datasets==1.0.5) (1.7.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.4->wildlife-datasets==1.0.5) (2024.2.0)\nBuilding wheels for collected packages: wildlife-datasets\n  Building wheel for wildlife-datasets (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for wildlife-datasets: filename=wildlife_datasets-1.0.5-py3-none-any.whl size=87510 sha256=0fe134563b25961d03b6487773e8c4c8386772bb4250b98493a27b8e5e312ff5\n  Stored in directory: /tmp/pip-ephem-wheel-cache-h6bvnunv/wheels/c5/e9/19/815dc8ac1a073b6769942e201b8776a681537b3da4bc2c60ab\nSuccessfully built wildlife-datasets\nInstalling collected packages: wildlife-datasets\nSuccessfully installed wildlife-datasets-1.0.5\nCollecting git+https://github.com/WildlifeDatasets/wildlife-tools\n  Cloning https://github.com/WildlifeDatasets/wildlife-tools to /tmp/pip-req-build-0a4ye604\n  Running command git clone --filter=blob:none --quiet https://github.com/WildlifeDatasets/wildlife-tools /tmp/pip-req-build-0a4ye604\n  Resolved https://github.com/WildlifeDatasets/wildlife-tools to commit 71aa4656d16afe4caae6d84af642bab81dc2d06d\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nCollecting gluefactory@ git+https://github.com/cvg/glue-factory.git@1f56839db2242929960d70f85bfac6c19ef2821c (from wildlife-tools==1.0.1)\n  Cloning https://github.com/cvg/glue-factory.git (to revision 1f56839db2242929960d70f85bfac6c19ef2821c) to /tmp/pip-install-o_5dv7mo/gluefactory_4693c6482207416c9399923d6c946534\n  Running command git clone --filter=blob:none --quiet https://github.com/cvg/glue-factory.git /tmp/pip-install-o_5dv7mo/gluefactory_4693c6482207416c9399923d6c946534\n  Running command git rev-parse -q --verify 'sha^1f56839db2242929960d70f85bfac6c19ef2821c'\n  Running command git fetch -q https://github.com/cvg/glue-factory.git 1f56839db2242929960d70f85bfac6c19ef2821c\n  Resolved https://github.com/cvg/glue-factory.git to commit 1f56839db2242929960d70f85bfac6c19ef2821c\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from wildlife-tools==1.0.1) (2.5.1+cu121)\nRequirement already satisfied: timm>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from wildlife-tools==1.0.1) (1.0.12)\nRequirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.10/dist-packages (from wildlife-tools==1.0.1) (1.26.4)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from wildlife-tools==1.0.1) (2.2.2)\nRequirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.10/dist-packages (from wildlife-tools==1.0.1) (4.67.1)\nRequirement already satisfied: opencv-python>=4.5.5.62 in /usr/local/lib/python3.10/dist-packages (from wildlife-tools==1.0.1) (4.10.0.84)\nRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from wildlife-tools==1.0.1) (11.0.0)\nRequirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from wildlife-tools==1.0.1) (1.2.2)\nRequirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from wildlife-tools==1.0.1) (2.0.8)\nRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from wildlife-tools==1.0.1) (2.17.1)\nCollecting pytorch_metric_learning (from wildlife-tools==1.0.1)\n  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: transformers>=4.30.2 in /usr/local/lib/python3.10/dist-packages (from wildlife-tools==1.0.1) (4.47.0)\nRequirement already satisfied: wildlife-datasets>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from wildlife-tools==1.0.1) (1.0.5)\nRequirement already satisfied: kornia>=0.6.12 in /usr/local/lib/python3.10/dist-packages (from wildlife-tools==1.0.1) (0.7.4)\nRequirement already satisfied: kornia-rs>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from kornia>=0.6.12->wildlife-tools==1.0.1) (0.1.8)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia>=0.6.12->wildlife-tools==1.0.1) (24.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.4->wildlife-tools==1.0.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.4->wildlife-tools==1.0.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.4->wildlife-tools==1.0.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.4->wildlife-tools==1.0.1) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.4->wildlife-tools==1.0.1) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.4->wildlife-tools==1.0.1) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->wildlife-tools==1.0.1) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->wildlife-tools==1.0.1) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->wildlife-tools==1.0.1) (2024.2)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.1->wildlife-tools==1.0.1) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.1->wildlife-tools==1.0.1) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.1->wildlife-tools==1.0.1) (3.5.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm>=0.9.2->wildlife-tools==1.0.1) (0.20.1+cu121)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm>=0.9.2->wildlife-tools==1.0.1) (6.0.2)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm>=0.9.2->wildlife-tools==1.0.1) (0.27.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm>=0.9.2->wildlife-tools==1.0.1) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->wildlife-tools==1.0.1) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->wildlife-tools==1.0.1) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->wildlife-tools==1.0.1) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->wildlife-tools==1.0.1) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->wildlife-tools==1.0.1) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->wildlife-tools==1.0.1) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.1->wildlife-tools==1.0.1) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.2->wildlife-tools==1.0.1) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.2->wildlife-tools==1.0.1) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.2->wildlife-tools==1.0.1) (0.21.0)\nRequirement already satisfied: matplotlib>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (3.7.5)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (3.2.0)\nRequirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (5.2.0)\nRequirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (1.6.17)\nCollecting lightglue@ git+https://github.com/cvg/LightGlue.git (from gluefactory@ git+https://github.com/cvg/glue-factory.git@1f56839db2242929960d70f85bfac6c19ef2821c->wildlife-tools==1.0.1)\n  Cloning https://github.com/cvg/LightGlue.git to /tmp/pip-install-o_5dv7mo/lightglue_145769f9cbc640049402ee96985c5d6e\n  Running command git clone --filter=blob:none --quiet https://github.com/cvg/LightGlue.git /tmp/pip-install-o_5dv7mo/lightglue_145769f9cbc640049402ee96985c5d6e\n  Resolved https://github.com/cvg/LightGlue.git to commit edb2b838efb2ecfe3f88097c5fad9887d95aedad\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from gluefactory@ git+https://github.com/cvg/glue-factory.git@1f56839db2242929960d70f85bfac6c19ef2821c->wildlife-tools==1.0.1) (3.12.1)\nRequirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (from gluefactory@ git+https://github.com/cvg/glue-factory.git@1f56839db2242929960d70f85bfac6c19ef2821c->wildlife-tools==1.0.1) (2.3.0)\nRequirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (from gluefactory@ git+https://github.com/cvg/glue-factory.git@1f56839db2242929960d70f85bfac6c19ef2821c->wildlife-tools==1.0.1) (1.4.20)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from gluefactory@ git+https://github.com/cvg/glue-factory.git@1f56839db2242929960d70f85bfac6c19ef2821c->wildlife-tools==1.0.1) (0.12.2)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->wildlife-tools==1.0.1) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->wildlife-tools==1.0.1) (1.68.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->wildlife-tools==1.0.1) (3.7)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->wildlife-tools==1.0.1) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->wildlife-tools==1.0.1) (75.1.0)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->wildlife-tools==1.0.1) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->wildlife-tools==1.0.1) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->wildlife-tools==1.0.1) (3.1.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (1.4.7)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->wildlife-tools==1.0.1) (3.0.2)\nRequirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations->gluefactory@ git+https://github.com/cvg/glue-factory.git@1f56839db2242929960d70f85bfac6c19ef2821c->wildlife-tools==1.0.1) (2.10.3)\nRequirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations->gluefactory@ git+https://github.com/cvg/glue-factory.git@1f56839db2242929960d70f85bfac6c19ef2821c->wildlife-tools==1.0.1) (0.0.19)\nRequirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations->gluefactory@ git+https://github.com/cvg/glue-factory.git@1f56839db2242929960d70f85bfac6c19ef2821c->wildlife-tools==1.0.1) (0.2.0)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations->gluefactory@ git+https://github.com/cvg/glue-factory.git@1f56839db2242929960d70f85bfac6c19ef2821c->wildlife-tools==1.0.1) (4.10.0.84)\nRequirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations->gluefactory@ git+https://github.com/cvg/glue-factory.git@1f56839db2242929960d70f85bfac6c19ef2821c->wildlife-tools==1.0.1) (3.11.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (0.3.8)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (0.70.16)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (3.11.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.30.2->wildlife-tools==1.0.1) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.30.2->wildlife-tools==1.0.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.30.2->wildlife-tools==1.0.1) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.30.2->wildlife-tools==1.0.1) (2024.12.14)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (4.12.3)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (8.0.4)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (6.2.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.4->wildlife-tools==1.0.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.4->wildlife-tools==1.0.1) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.4->wildlife-tools==1.0.1) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.4->wildlife-tools==1.0.1) (2024.2.0)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf->gluefactory@ git+https://github.com/cvg/glue-factory.git@1f56839db2242929960d70f85bfac6c19ef2821c->wildlife-tools==1.0.1) (4.9.3)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (1.18.3)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.4->wildlife-tools==1.0.1) (2024.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->gluefactory@ git+https://github.com/cvg/glue-factory.git@1f56839db2242929960d70f85bfac6c19ef2821c->wildlife-tools==1.0.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->gluefactory@ git+https://github.com/cvg/glue-factory.git@1f56839db2242929960d70f85bfac6c19ef2821c->wildlife-tools==1.0.1) (2.27.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (2.6)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (1.3)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->wildlife-datasets>=0.3.4->wildlife-tools==1.0.1) (1.7.1)\nDownloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: wildlife-tools, gluefactory, lightglue\n  Building wheel for wildlife-tools (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for wildlife-tools: filename=wildlife_tools-1.0.1-py3-none-any.whl size=33804 sha256=56276e757016d7ef86f8422124d84f2cdb74d9823e42866c5270190e0dfeb552\n  Stored in directory: /tmp/pip-ephem-wheel-cache-88ipp72g/wheels/74/75/ab/1c26a4ecc35c1bff78b3fe64f50258d593de78f1022f73067d\n  Building wheel for gluefactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gluefactory: filename=gluefactory-0.0-py3-none-any.whl size=212968 sha256=56a443f7c8a085ecd11f7e6e94155115c6cb63b059b2f5df510a46ed7d4added\n  Stored in directory: /root/.cache/pip/wheels/81/ae/90/9c06c232fc717f2f9188a94a5ebf1f6e6bb7a76929467f0196\n  Building wheel for lightglue (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for lightglue: filename=lightglue-0.0-py3-none-any.whl size=39504 sha256=e100fe6ac961ca8ed365d665193ccbb4613e2204cf2a4349566615934f0b63b1\n  Stored in directory: /tmp/pip-ephem-wheel-cache-88ipp72g/wheels/07/dc/a1/22bc17d3d78e58fbd145e264d6736aab70959fbf872c80ddb9\nSuccessfully built wildlife-tools gluefactory lightglue\nInstalling collected packages: lightglue, pytorch_metric_learning, gluefactory, wildlife-tools\nSuccessfully installed gluefactory-0.0 lightglue-0.0 pytorch_metric_learning-2.8.1 wildlife-tools-1.0.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Dependencies import\nWe load all the required packages and then define the function `create_sample_submission`, which converts provided predictions and a submission file for the competition.","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport timm\nimport torchvision.transforms as T\nfrom wildlife_datasets.datasets import AnimalCLEF2025\nfrom wildlife_tools.features import DeepFeatures\nfrom wildlife_tools.similarity import CosineSimilarity\ndef create_sample_submission(dataset_query, predictions, file_name='sample_submission.csv'):\n    df = pd.DataFrame({\n        'image_id': dataset_query.metadata['image_id'],\n        'identity': predictions\n    })\n    df.to_csv(file_name, index=False)","metadata":{"execution":{"iopub.status.busy":"2025-02-28T19:02:48.989124Z","iopub.execute_input":"2025-02-28T19:02:48.989478Z","iopub.status.idle":"2025-02-28T19:03:14.017947Z","shell.execute_reply.started":"2025-02-28T19:02:48.989440Z","shell.execute_reply":"2025-02-28T19:03:14.017225Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"We need to specify the `root`, where the data are stored and then two image transformations. \n1. The first transform only resizes the images and is used for visualization.\n2. The second transform also converts it to torch tensor and is used for operations on neural networks.","metadata":{}},{"cell_type":"code","source":"root = '/kaggle/input/animal-clef-2025'\ntransform_display = T.Compose([\n    T.Resize([384, 384]),\n    ])\ntransform = T.Compose([\n    *transform_display.transforms,\n    T.ToTensor(),\n    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n    ])","metadata":{"execution":{"iopub.status.busy":"2025-02-28T19:03:14.022237Z","iopub.execute_input":"2025-02-28T19:03:14.022559Z","iopub.status.idle":"2025-02-28T19:03:14.028039Z","shell.execute_reply.started":"2025-02-28T19:03:14.022528Z","shell.execute_reply":"2025-02-28T19:03:14.027109Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### 📊 Visualizing Data\n\nSince `AnimalCLEF2015` is the child class of `datasets.WildlifeDataset` from [wildlife-datasets](https://github.com/WildlifeDatasets/wildlife-datasets/blob/main/wildlife_datasets/datasets/datasets.py), it inherits all its methods and attributes. The following code specify which `transform` we want to use while loading images and that we want to load labels alongside images.","metadata":{}},{"cell_type":"code","source":"dataset = AnimalCLEF2025(root, transform=transform_display, load_label=True)","metadata":{"execution":{"iopub.status.busy":"2025-02-28T19:03:14.031146Z","iopub.execute_input":"2025-02-28T19:03:14.031459Z","iopub.status.idle":"2025-02-28T19:03:55.560857Z","shell.execute_reply.started":"2025-02-28T19:03:14.031430Z","shell.execute_reply":"2025-02-28T19:03:55.559854Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"📌 **Plotting a sample grid** of the data. We can see that all animals in the testing sets are turtles. The column `dataset` states that all the photos come from the SeaTurtleID2022 dataset.","metadata":{}},{"cell_type":"code","source":"dataset.plot_grid()\ndataset.metadata","metadata":{"execution":{"iopub.status.busy":"2025-02-28T19:03:55.562512Z","iopub.execute_input":"2025-02-28T19:03:55.562888Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       image_id            identity  \\\n0             0  LynxID2025_lynx_37   \n1             1  LynxID2025_lynx_37   \n2             2  LynxID2025_lynx_49   \n3             3                 NaN   \n4             4  LynxID2025_lynx_13   \n...         ...                 ...   \n15204     15204                 NaN   \n15205     15205                 NaN   \n15206     15206                 NaN   \n15207     15207                 NaN   \n15208     15208                 NaN   \n\n                                                    path        date  \\\n0      images/LynxID2025/database/000f9ee1aad063a4485...         NaN   \n1      images/LynxID2025/database/0020edb6689e9f78462...         NaN   \n2      images/LynxID2025/database/003152e4145b5b69400...         NaN   \n3      images/LynxID2025/query/003b89301c7b9f6d18f722...         NaN   \n4      images/LynxID2025/database/003c3f82011e9c3f849...         NaN   \n...                                                  ...         ...   \n15204  images/SeaTurtleID2022/query/images/fecd2dfed0...  2024-06-07   \n15205  images/SeaTurtleID2022/query/images/ff1a0c812b...  2023-06-28   \n15206  images/SeaTurtleID2022/query/images/ff22f1cfa6...  2024-06-09   \n15207  images/SeaTurtleID2022/query/images/ff5d5116d1...  2023-06-21   \n15208  images/SeaTurtleID2022/query/images/ff7f522363...  2023-06-13   \n\n      orientation            species     split          dataset  \n0           right               lynx  database       LynxID2025  \n1            left               lynx  database       LynxID2025  \n2            left               lynx  database       LynxID2025  \n3            back               lynx     query       LynxID2025  \n4           right               lynx  database       LynxID2025  \n...           ...                ...       ...              ...  \n15204         NaN  loggerhead turtle     query  SeaTurtleID2022  \n15205         NaN  loggerhead turtle     query  SeaTurtleID2022  \n15206         NaN  loggerhead turtle     query  SeaTurtleID2022  \n15207         NaN  loggerhead turtle     query  SeaTurtleID2022  \n15208         NaN  loggerhead turtle     query  SeaTurtleID2022  \n\n[15209 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>identity</th>\n      <th>path</th>\n      <th>date</th>\n      <th>orientation</th>\n      <th>species</th>\n      <th>split</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>LynxID2025_lynx_37</td>\n      <td>images/LynxID2025/database/000f9ee1aad063a4485...</td>\n      <td>NaN</td>\n      <td>right</td>\n      <td>lynx</td>\n      <td>database</td>\n      <td>LynxID2025</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>LynxID2025_lynx_37</td>\n      <td>images/LynxID2025/database/0020edb6689e9f78462...</td>\n      <td>NaN</td>\n      <td>left</td>\n      <td>lynx</td>\n      <td>database</td>\n      <td>LynxID2025</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>LynxID2025_lynx_49</td>\n      <td>images/LynxID2025/database/003152e4145b5b69400...</td>\n      <td>NaN</td>\n      <td>left</td>\n      <td>lynx</td>\n      <td>database</td>\n      <td>LynxID2025</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>images/LynxID2025/query/003b89301c7b9f6d18f722...</td>\n      <td>NaN</td>\n      <td>back</td>\n      <td>lynx</td>\n      <td>query</td>\n      <td>LynxID2025</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>LynxID2025_lynx_13</td>\n      <td>images/LynxID2025/database/003c3f82011e9c3f849...</td>\n      <td>NaN</td>\n      <td>right</td>\n      <td>lynx</td>\n      <td>database</td>\n      <td>LynxID2025</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15204</th>\n      <td>15204</td>\n      <td>NaN</td>\n      <td>images/SeaTurtleID2022/query/images/fecd2dfed0...</td>\n      <td>2024-06-07</td>\n      <td>NaN</td>\n      <td>loggerhead turtle</td>\n      <td>query</td>\n      <td>SeaTurtleID2022</td>\n    </tr>\n    <tr>\n      <th>15205</th>\n      <td>15205</td>\n      <td>NaN</td>\n      <td>images/SeaTurtleID2022/query/images/ff1a0c812b...</td>\n      <td>2023-06-28</td>\n      <td>NaN</td>\n      <td>loggerhead turtle</td>\n      <td>query</td>\n      <td>SeaTurtleID2022</td>\n    </tr>\n    <tr>\n      <th>15206</th>\n      <td>15206</td>\n      <td>NaN</td>\n      <td>images/SeaTurtleID2022/query/images/ff22f1cfa6...</td>\n      <td>2024-06-09</td>\n      <td>NaN</td>\n      <td>loggerhead turtle</td>\n      <td>query</td>\n      <td>SeaTurtleID2022</td>\n    </tr>\n    <tr>\n      <th>15207</th>\n      <td>15207</td>\n      <td>NaN</td>\n      <td>images/SeaTurtleID2022/query/images/ff5d5116d1...</td>\n      <td>2023-06-21</td>\n      <td>NaN</td>\n      <td>loggerhead turtle</td>\n      <td>query</td>\n      <td>SeaTurtleID2022</td>\n    </tr>\n    <tr>\n      <th>15208</th>\n      <td>15208</td>\n      <td>NaN</td>\n      <td>images/SeaTurtleID2022/query/images/ff7f522363...</td>\n      <td>2023-06-13</td>\n      <td>NaN</td>\n      <td>loggerhead turtle</td>\n      <td>query</td>\n      <td>SeaTurtleID2022</td>\n    </tr>\n  </tbody>\n</table>\n<p>15209 rows × 8 columns</p>\n</div>"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"This is confirmed by showing all datasets from which the data is composed of.","metadata":{}},{"cell_type":"code","source":"dataset.metadata[['dataset', 'split']].value_counts()","metadata":{"execution":{"iopub.status.idle":"2025-02-28T19:03:56.605203Z","shell.execute_reply.started":"2025-02-28T19:03:56.591181Z","shell.execute_reply":"2025-02-28T19:03:56.604486Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"dataset           split   \nSeaTurtleID2022   database    8729\nLynxID2025        database    2957\nSalamanderID2025  database    1388\nLynxID2025        query        946\nSalamanderID2025  query        689\nSeaTurtleID2022   query        500\nName: count, dtype: int64"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"Now, we can plot the data of any dataset. Here we do it for the SeaTurtleID2022. The images are the same as in the query set. The goal for each image from the query set will be to determine its identity from the database (it will always be in the form `SeaTurtleID2022_t???` or to decide that it is a new individual (it is not present in the database).","metadata":{}},{"cell_type":"code","source":"idx = dataset.metadata['identity'].str.startswith('SeaTurtleID2022')\nidx[idx.isnull()] = False\ndataset.plot_grid(idx=idx);","metadata":{"execution":{"iopub.status.busy":"2025-02-28T19:03:56.605917Z","iopub.execute_input":"2025-02-28T19:03:56.606158Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inference with MegaDescriptor\n\nInstead of training a classifier, we can just use out of the shelf pretrained models - [MegaDescriptor](https://huggingface.co/BVRA/MegaDescriptor-L-384). We use MegaDescriptor to extract features from all images. \n\n**Note:** _It is highly recommended to use the GPU acceleration._","metadata":{}},{"cell_type":"code","source":"# Loading the dataset\ndataset = AnimalCLEF2025(root, transform=transform, load_label=True)\ndataset_database = dataset.get_subset(dataset.metadata['split'] == 'database')\ndataset_query = dataset.get_subset(dataset.metadata['split'] == 'query')\nn_query = len(dataset_query)","metadata":{"execution":{"iopub.execute_input":"2025-02-28T19:03:57.138924Z","iopub.status.idle":"2025-02-28T19:04:04.314012Z","shell.execute_reply.started":"2025-02-28T19:03:57.138899Z","shell.execute_reply":"2025-02-28T19:04:04.313050Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#Loading the model\nname = 'hf-hub:BVRA/MegaDescriptor-L-384'\ndevice = 'cuda'\nmodel = timm.create_model(name, num_classes=0, pretrained=True)\nextractor = DeepFeatures(model, device=device, batch_size=32, num_workers=0)\nfeatures_database = extractor(dataset_database)\nfeatures_query = extractor(dataset_query)","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-02-28T19:04:04.315150Z","iopub.execute_input":"2025-02-28T19:04:04.315519Z","iopub.status.idle":"2025-02-28T19:20:12.560429Z","shell.execute_reply.started":"2025-02-28T19:04:04.315468Z","shell.execute_reply":"2025-02-28T19:20:12.559391Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a625a115a89447b8eda44134431297b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b0fbe903267440282a1a1e40c69ae3c"}},"metadata":{}},{"name":"stderr","text":"100%|█████████████████████████████████████████████████████████████| 409/409 [13:09<00:00,  1.93s/it]\n100%|███████████████████████████████████████████████████████████████| 67/67 [02:42<00:00,  2.43s/it]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"Here we extract the similarity between the images. The similarity equals to the cosine similarity between the corresponding feature vectors. Since the cosine similarity reflects the angle between the feature vectors, high similarity means that the feature vectors are close to each other and should depict the same individual.","metadata":{}},{"cell_type":"code","source":"similarity = CosineSimilarity()(features_query, features_database)","metadata":{"execution":{"iopub.status.busy":"2025-02-28T19:20:12.561337Z","iopub.execute_input":"2025-02-28T19:20:12.561642Z","iopub.status.idle":"2025-02-28T19:20:12.953383Z","shell.execute_reply.started":"2025-02-28T19:20:12.561617Z","shell.execute_reply":"2025-02-28T19:20:12.952443Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"For each query image we extract the closest image as predicted by MegaDescriptor. Their indices are stored in `pred_idx` and the similarity score of the top match in `pred_scores`.","metadata":{}},{"cell_type":"code","source":"pred_idx = similarity.argsort(axis=1)[:,-1]\npred_scores = similarity[range(n_query), pred_idx]","metadata":{"execution":{"iopub.status.busy":"2025-02-28T19:20:12.954293Z","iopub.execute_input":"2025-02-28T19:20:12.954600Z","iopub.status.idle":"2025-02-28T19:20:13.718443Z","shell.execute_reply.started":"2025-02-28T19:20:12.954570Z","shell.execute_reply":"2025-02-28T19:20:13.717769Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"This is sufficient to perform predictions as shown below in `predictions`. However, we also need to predict whether the individual is new. We utilize the simplest idea and predict that the individual is new whenever the similarity score of the top prediction is below a certain threshold which we arbirtarily selected as 0.6. We create a submission file, which scores 30.0% on the public leaderboard.","metadata":{}},{"cell_type":"code","source":"new_individual = 'new_individual'\nthreshold = 0.6\nlabels = dataset_database.labels_string\npredictions = labels[pred_idx]\npredictions[pred_scores < threshold] = new_individual\ncreate_sample_submission(dataset_query, predictions, file_name='sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2025-02-28T19:20:13.719226Z","iopub.execute_input":"2025-02-28T19:20:13.719536Z","iopub.status.idle":"2025-02-28T19:20:13.731916Z","shell.execute_reply.started":"2025-02-28T19:20:13.719502Z","shell.execute_reply":"2025-02-28T19:20:13.731207Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}