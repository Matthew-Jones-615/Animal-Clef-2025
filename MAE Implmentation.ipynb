{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91451,"databundleVersionId":11223220,"sourceType":"competition"},{"sourceId":226395403,"sourceType":"kernelVersion"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from wildlife_datasets.datasets import AnimalCLEF2025\n\ndataset = AnimalCLEF2025(root)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:27:51.659971Z","iopub.execute_input":"2025-05-03T19:27:51.660855Z","iopub.status.idle":"2025-05-03T19:27:51.683368Z","shell.execute_reply.started":"2025-05-03T19:27:51.660807Z","shell.execute_reply":"2025-05-03T19:27:51.682001Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/33698039.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwildlife_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnimalCLEF2025\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnimalCLEF2025\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wildlife_datasets'"],"ename":"ModuleNotFoundError","evalue":"No module named 'wildlife_datasets'","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"from huggingface_hub import snapshot_download\nsnapshot_download(\"facebook/vit-base-patch16-224\", cache_dir=\"./vit_weights\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:46:04.488205Z","iopub.execute_input":"2025-05-05T17:46:04.488517Z","iopub.status.idle":"2025-05-05T17:46:36.536080Z","shell.execute_reply.started":"2025-05-05T17:46:04.488493Z","shell.execute_reply":"2025-05-05T17:46:36.534695Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             sock = connection.create_connection(\n\u001b[0m\u001b[1;32m    199\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mNameResolutionError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrap_proxy_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLSocket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaierror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNameResolutionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketTimeout\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameResolutionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7cf638c08f50>: Failed to resolve 'huggingface.co' ([Errno -3] Temporary failure in name resolution)","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    842\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreason\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/facebook/vit-base-patch16-224/revision/main (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7cf638c08f50>: Failed to resolve 'huggingface.co' ([Errno -3] Temporary failure in name resolution)\"))","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/_snapshot_download.py\u001b[0m in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[0m\n\u001b[1;32m    154\u001b[0m             )\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mrepo_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProxyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mrepo_info\u001b[0;34m(self, repo_id, revision, repo_type, timeout, files_metadata, expand, token)\u001b[0m\n\u001b[1;32m   2806\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsupported repo type.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2807\u001b[0;31m         return method(\n\u001b[0m\u001b[1;32m   2808\u001b[0m             \u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mmodel_info\u001b[0;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, expand, token)\u001b[0m\n\u001b[1;32m   2590\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"expand\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2591\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2592\u001b[0m         \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allow_redirects\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mConnectionError\u001b[0m: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/facebook/vit-base-patch16-224/revision/main (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7cf638c08f50>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: d13b9ffd-a082-45bb-a488-a3815c8590de)')","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1063268740.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msnapshot_download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msnapshot_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/vit-base-patch16-224\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./vit_weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/_snapshot_download.py\u001b[0m in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;31m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             raise LocalEntryNotFoundError(\n\u001b[0m\u001b[1;32m    236\u001b[0m                 \u001b[0;34m\"An error happened while trying to locate the files on the Hub and we cannot find the appropriate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0;34m\" snapshot folder for the specified revision on the local disk. Please check your internet connection\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLocalEntryNotFoundError\u001b[0m: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again."],"ename":"LocalEntryNotFoundError","evalue":"An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again.","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport timm\nimport pandas as pd\nfrom PIL import Image\nimport os\nimport json\nfrom tqdm import tqdm\n\n# ===== Configuration =====\nroot_dir = \"/kaggle/input/animal-clef-2025\"\nmetadata_path = os.path.join(root_dir, \"metadata.csv\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nimage_size = 224\nbatch_size = 32\nnum_workers = 2\nconfidence_threshold = 0.80\nnum_epochs = 250\ncheckpoint_dir = \"./checkpoints\"\nos.makedirs(checkpoint_dir, exist_ok=True)\n\n# ===== Load metadata =====\ndf = pd.read_csv(metadata_path)\n\n# ===== Dataset Class =====\nclass AnimalReIDDataset(Dataset):\n    def __init__(self, dataframe, transform):\n        self.df = dataframe.reset_index(drop=True)\n        self.transform = transform\n        self.label2id = {label: i for i, label in enumerate(sorted(self.df['identity'].unique()))}\n        self.id2label = {v: k for k, v in self.label2id.items()}\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(root_dir, row[\"path\"])\n        img = Image.open(img_path).convert(\"RGB\")\n        img = self.transform(img)\n        label = self.label2id[row[\"identity\"]]\n        return img, label\n\n# ===== Image Transform =====\ntransform = transforms.Compose([\n    transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n])\n\n# ===== Build Dataset and Dataloader =====\ntrain_df = df[(df[\"split\"] == \"database\") & (df[\"identity\"].notna())]\ntrain_dataset = AnimalReIDDataset(train_df, transform)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n\n# ===== Model Definition =====\nclass MAEClassifier(nn.Module):\n    def __init__(self, num_classes, freeze_encoder=True):\n        super(MAEClassifier, self).__init__()\n        self.encoder = timm.create_model(\"vit_base_patch16_224\", pretrained=True, num_classes=0)\n        self.encoder_frozen = freeze_encoder\n\n        if self.encoder_frozen:\n            for param in self.encoder.parameters():\n                param.requires_grad = False\n\n        self.classifier = nn.Linear(self.encoder.num_features, num_classes)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        return self.classifier(x)\n\n    def unfreeze_encoder(self, num_blocks=6):\n        if self.encoder_frozen:\n            print(f\"Unfreezing last {num_blocks} encoder blocks for fine-tuning...\")\n            for block in self.encoder.blocks[-num_blocks:]:\n                for param in block.parameters():\n                    param.requires_grad = True\n            for param in self.encoder.norm.parameters():\n                param.requires_grad = True\n            self.encoder_frozen = False\n\n# ===== Initialize or Resume Model =====\nmodel = MAEClassifier(num_classes=len(train_dataset.label2id), freeze_encoder=True).to(device)\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n\nstart_epoch = 0\nbest_loss = float('inf')\ncheckpoint_path = os.path.join(checkpoint_dir, \"last_checkpoint.pth\")\n\nif os.path.exists(checkpoint_path):\n    print(\"Resuming from last checkpoint...\")\n    checkpoint = torch.load(checkpoint_path, map_location=device)\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    start_epoch = checkpoint[\"epoch\"] + 1\n    best_loss = checkpoint[\"best_loss\"]\n    model.encoder_frozen = checkpoint.get(\"encoder_frozen\", True)\n    print(f\"Resumed from epoch {start_epoch} with best loss {best_loss:.4f}\")\n\noptimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs - start_epoch)\nscaler = torch.cuda.amp.GradScaler()\n\n# ===== Training Loop =====\nfor epoch in range(start_epoch, num_epochs):\n    if epoch == 10 and model.encoder_frozen:\n        model.unfreeze_encoder(num_blocks=6)\n        optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-4)\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs - epoch)\n\n    model.train()\n    total_loss = 0\n    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n    for images, labels in loop:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n\n        with torch.cuda.amp.autocast():\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n        scaler.scale(loss).backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        scaler.step(optimizer)\n        scaler.update()\n\n        total_loss += loss.item()\n        loop.set_postfix(loss=loss.item())\n\n    scheduler.step()\n    print(f\"Epoch {epoch+1}/{num_epochs} - Total Loss: {total_loss:.4f}\")\n\n    if total_loss < best_loss:\n        best_loss = total_loss\n        torch.save(model.state_dict(), os.path.join(checkpoint_dir, \"best_model.pth\"))\n        print(\" Best model saved.\")\n\n    if (epoch + 1) % 20 == 0:\n        torch.save({\n            \"epoch\": epoch,\n            \"model_state_dict\": model.state_dict(),\n            \"best_loss\": best_loss,\n            \"encoder_frozen\": model.encoder_frozen\n        }, os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1}.pth\"))\n        print(f\"Checkpoint saved at epoch {epoch+1}\")\n\ntorch.save({\n    \"epoch\": epoch,\n    \"model_state_dict\": model.state_dict(),\n    \"best_loss\": best_loss,\n    \"encoder_frozen\": model.encoder_frozen\n}, checkpoint_path)\nprint(\"Last checkpoint saved.\")\n\nwith open(os.path.join(checkpoint_dir, \"label_map.json\"), \"w\") as f:\n    json.dump(train_dataset.id2label, f)\nprint(\" Label map saved.\")\n\n\n\n\n\n####you can run all the above at once for training then run the one below \n\n\n\n\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T13:01:38.359107Z","iopub.execute_input":"2025-05-07T13:01:38.359387Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e625276bf90439186e364f3cde817b1"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_31/3235166995.py:108: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\nEpoch 1/250:   0%|          | 0/409 [00:00<?, ?it/s]/tmp/ipykernel_31/3235166995.py:124: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/250 - Total Loss: 2499.9117\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/250 - Total Loss: 2239.5651\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/250 - Total Loss: 2156.8118\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/250 - Total Loss: 2097.8204\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/250 - Total Loss: 2049.8361\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/250 - Total Loss: 2011.0941\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/250 - Total Loss: 1980.5683\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/250 - Total Loss: 1944.4984\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/250 - Total Loss: 1912.2999\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/250 - Total Loss: 1881.9845\n Best model saved.\nUnfreezing last 6 encoder blocks for fine-tuning...\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/250 - Total Loss: 1421.1053\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/250 - Total Loss: 1083.9597\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/250 - Total Loss: 903.1479\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/250 - Total Loss: 778.5106\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/250 - Total Loss: 688.1588\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/250 - Total Loss: 599.2748\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/250 - Total Loss: 594.4878\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/250 - Total Loss: 562.0109\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/250 - Total Loss: 539.1511\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/250 - Total Loss: 524.5387\n Best model saved.\nCheckpoint saved at epoch 20\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21/250 - Total Loss: 513.9394\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22/250 - Total Loss: 495.7649\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23/250 - Total Loss: 487.2299\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24/250 - Total Loss: 484.1017\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25/250 - Total Loss: 480.4074\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26/250 - Total Loss: 477.7402\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27/250 - Total Loss: 472.2629\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28/250 - Total Loss: 468.9397\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29/250 - Total Loss: 467.6421\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30/250 - Total Loss: 466.3239\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 31/250 - Total Loss: 465.7701\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 32/250 - Total Loss: 464.3702\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 33/250 - Total Loss: 463.7789\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 34/250 - Total Loss: 467.1166\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 35/250 - Total Loss: 466.7836\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 36/250 - Total Loss: 465.6167\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 37/250 - Total Loss: 462.9671\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 38/250 - Total Loss: 461.8429\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 39/250 - Total Loss: 457.1085\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 40/250 - Total Loss: 455.2278\n Best model saved.\nCheckpoint saved at epoch 40\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 41/250 - Total Loss: 454.0866\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 42/250 - Total Loss: 453.4291\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 43/250 - Total Loss: 452.7997\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 44/250 - Total Loss: 452.0289\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 45/250 - Total Loss: 451.5159\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 46/250 - Total Loss: 450.6421\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 47/250 - Total Loss: 450.6023\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 48/250 - Total Loss: 449.8192\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 49/250 - Total Loss: 449.2373\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 50/250 - Total Loss: 449.0377\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 51/250 - Total Loss: 448.3159\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 52/250 - Total Loss: 448.1705\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 53/250 - Total Loss: 447.5078\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 54/250 - Total Loss: 446.2238\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 55/250 - Total Loss: 446.9246\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 56/250 - Total Loss: 446.3559\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 57/250 - Total Loss: 446.2549\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 58/250 - Total Loss: 445.8619\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 59/250 - Total Loss: 447.7929\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 60/250 - Total Loss: 448.8202\nCheckpoint saved at epoch 60\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 61/250 - Total Loss: 448.0874\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 62/250 - Total Loss: 447.8789\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 63/250 - Total Loss: 446.5089\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 64/250 - Total Loss: 443.9175\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 65/250 - Total Loss: 443.9319\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 66/250 - Total Loss: 445.1978\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 67/250 - Total Loss: 444.7724\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 68/250 - Total Loss: 444.5940\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 69/250 - Total Loss: 443.8910\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 70/250 - Total Loss: 442.3767\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 71/250 - Total Loss: 440.5229\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 72/250 - Total Loss: 439.9575\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 73/250 - Total Loss: 439.7917\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 74/250 - Total Loss: 439.5638\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 75/250 - Total Loss: 438.9300\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 76/250 - Total Loss: 439.0779\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 77/250 - Total Loss: 438.8719\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 78/250 - Total Loss: 438.7442\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 79/250 - Total Loss: 438.2961\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 80/250 - Total Loss: 438.1022\n Best model saved.\nCheckpoint saved at epoch 80\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 81/250 - Total Loss: 437.2170\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 82/250 - Total Loss: 437.6698\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 83/250 - Total Loss: 437.7018\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 84/250 - Total Loss: 437.5334\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 85/250 - Total Loss: 437.4652\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 86/250 - Total Loss: 437.0179\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 87/250 - Total Loss: 436.9501\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 88/250 - Total Loss: 436.8356\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 89/250 - Total Loss: 436.5854\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 90/250 - Total Loss: 436.3619\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 91/250 - Total Loss: 436.1508\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 92/250 - Total Loss: 436.1057\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 93/250 - Total Loss: 435.9489\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 94/250 - Total Loss: 435.6878\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 95/250 - Total Loss: 435.5230\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 96/250 - Total Loss: 435.6410\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 97/250 - Total Loss: 434.8469\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 99/250 - Total Loss: 435.0535\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 100/250 - Total Loss: 434.9239\nCheckpoint saved at epoch 100\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 101/250 - Total Loss: 434.8831\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 102/250 - Total Loss: 434.6390\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 103/250 - Total Loss: 434.6361\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 104/250 - Total Loss: 434.4084\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 105/250 - Total Loss: 434.3330\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 106/250 - Total Loss: 434.2666\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 107/250 - Total Loss: 434.0867\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 108/250 - Total Loss: 433.4426\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 109/250 - Total Loss: 433.0848\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 110/250 - Total Loss: 433.0078\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 111/250 - Total Loss: 432.8664\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 112/250 - Total Loss: 432.9480\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 113/250 - Total Loss: 432.7389\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 114/250 - Total Loss: 432.7419\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 115/250 - Total Loss: 432.6516\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 116/250 - Total Loss: 432.5945\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 117/250 - Total Loss: 432.5015\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 118/250 - Total Loss: 432.4064\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 119/250 - Total Loss: 432.4473\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 120/250 - Total Loss: 432.2937\n Best model saved.\nCheckpoint saved at epoch 120\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 121/250 - Total Loss: 432.1809\n Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 122/250 - Total Loss: 432.2279\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 123/250 - Total Loss: 433.0517\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 124/250 - Total Loss: 434.0378\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 125/250 - Total Loss: 433.9860\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 126/250 - Total Loss: 433.6739\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 127/250 - Total Loss: 433.5586\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 128/250 - Total Loss: 433.3189\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 129/250 - Total Loss: 432.4508\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 130/250 - Total Loss: 432.2581\n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 131/250 - Total Loss: 432.1827\n","output_type":"stream"},{"name":"stderr","text":"Epoch 132/250:  51%|█████     | 209/409 [01:09<01:01,  3.26it/s, loss=1.06]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"###Inference code\n\nimport torch.nn.functional as F \ncheckpoint_dir = \"./checkpoints\"\ncheckpoint_path = os.path.join(checkpoint_dir, \"best_model.pth\")\nlabel_map_path = os.path.join(checkpoint_dir, \"label_map.json\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nimage_size = 224\nconfidence_threshold = 0.80\n\n# ===== Load metadata and label map =====\ndf = pd.read_csv(metadata_path)\nwith open(label_map_path, \"r\") as f:\n    id2label = json.load(f)\nlabel_map = {int(k): v for k, v in id2label.items()}\nnum_classes = len(label_map)\n\n# ===== Transform =====\ntransform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n])\n\n# ===== Model Definition =====\nclass MAEClassifier(torch.nn.Module):\n    def __init__(self, num_classes):\n        super(MAEClassifier, self).__init__()\n        import timm\n        self.encoder = timm.create_model(\"vit_base_patch16_224\", pretrained=False, num_classes=0)\n        self.classifier = torch.nn.Linear(self.encoder.num_features, num_classes)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        return self.classifier(x)\n\n# ===== Load Model from Checkpoint =====\nmodel = MAEClassifier(num_classes=num_classes).to(device)\nmodel.load_state_dict(torch.load(checkpoint_path, map_location=device))\nmodel.eval()\nprint(f\" Loaded checkpoint from {checkpoint_path}\")\n\n# ===== Evaluate on Query Set =====\nresults = []\nquery_df = df[df[\"split\"] == \"query\"].reset_index(drop=True)\n\nfor _, row in tqdm(query_df.iterrows(), total=len(query_df), desc=\"Evaluating\"):\n    img_path = os.path.join(root_dir, row[\"path\"])\n    img = Image.open(img_path).convert(\"RGB\")\n    img_tensor = transform(img).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        logits = model(img_tensor)\n        probs = F.softmax(logits, dim=1)\n        max_prob, pred_class = torch.max(probs, dim=1)\n        identity = label_map[pred_class.item()] if max_prob.item() >= confidence_threshold else \"new_individual\"\n\n    results.append({\n        \"image_id\": row[\"image_id\"],\n        \"identity\": identity\n    })\n\n# ===== Save Submission =====\nsubmission_df = pd.DataFrame(results)\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\" Final classifier-based submission saved as 'submission.csv'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}